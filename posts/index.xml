<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on mamonas.dev</title>
    <link>https://mamonas.dev/posts/</link>
    <description>Recent content in Posts on mamonas.dev</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 18 Aug 2025 22:04:52 +0300</lastBuildDate><atom:link href="https://mamonas.dev/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Which Compression Saves the Most Storage $? (gzip, Snappy, LZ4, zstd)</title>
      <link>https://mamonas.dev/posts/which-compression-algorithm-saves-most/</link>
      <pubDate>Mon, 18 Aug 2025 22:04:52 +0300</pubDate>
      
      <guid>https://mamonas.dev/posts/which-compression-algorithm-saves-most/</guid>
      <description>&lt;p&gt;Compression setting are set and forget in most cases, if it works no reason to change it. I decided to look into and see whether it would be beneficial to review the defaults and if it could save money. I covered most of the algorithms discussed in this post previously in &lt;a href=&#34;https://mamonas.dev/posts/compression-algorithms-you-probably-inherited/&#34;&gt;Compression Algorithms You Probably Inherited&lt;/a&gt;, where I summarized the info I collected while researching. But I wanted to sanity-check the findings myself and decided to run some benchmarks. This should help me see if compression actually makes a difference for storage costs.&lt;/p&gt;</description>
      <content>&lt;p&gt;Compression setting are set and forget in most cases, if it works no reason to change it. I decided to look into and see whether it would be beneficial to review the defaults and if it could save money. I covered most of the algorithms discussed in this post previously in &lt;a href=&#34;https://mamonas.dev/posts/compression-algorithms-you-probably-inherited/&#34;&gt;Compression Algorithms You Probably Inherited&lt;/a&gt;, where I summarized the info I collected while researching. But I wanted to sanity-check the findings myself and decided to run some benchmarks. This should help me see if compression actually makes a difference for storage costs.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;what-i-tested&#34;&gt;What I Tested&lt;/h2&gt;
&lt;p&gt;To keep things real, I used actual data: &lt;a href=&#34;https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page&#34;&gt;NYC TLC trip records&lt;/a&gt;. Each month’s data file was ~500MB. I combined a few to get files at 500MB, 1.6GB, 3.9GB, and 6.6GB.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Compression algorithms tested:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;gzip&lt;/li&gt;
&lt;li&gt;Snappy&lt;/li&gt;
&lt;li&gt;LZ4&lt;/li&gt;
&lt;li&gt;zstd at levels 1, 3, 9, and 19&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Environment:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MacBook Pro (2021, M1 Pro, 16GB RAM)&lt;/li&gt;
&lt;li&gt;Single-threaded runs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I couldn’t process the largest file with my setup. SKILL ISSUE. In reality, I didn’t bother trying to fix it, multi-threading and batching the compression should have allowed me to do it, but I already had the 3 other files to work with.&lt;/p&gt;
&lt;p&gt;To run the benchmarks, I built a small CLI tool: &lt;a href=&#34;https://github.com/KonMam/compressbench&#34;&gt;compressbench&lt;/a&gt;. It’s publicly available and it currently supports gzip, snappy, lz4, and zstd (with levels) and outputs compression/decompression benchmarks for Parquet files. I’m planning to add support for custom codecs later, mostly so I can benchmark my own RLE, Huffman, and LZ77 implementations.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://mamonas.dev/posts/which-compression-algorithm-saves-most/image-1.png&#34; alt=&#34;Compression Ratio/Time/Throughput, Decompression Throughput&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;compression-ratio&#34;&gt;Compression Ratio&lt;/h3&gt;
&lt;p&gt;If you only care about the smallest file, zstd-19 and gzip come out ahead. But the margin over zstd-3 is tiny, and you pay for it heavily elsewhere. Snappy and LZ4 compress to about 1.12 - just enough to make it look like they tried. But if that’s all you have, 12% savings is still better than no savings.&lt;/p&gt;
&lt;p&gt;For most storage use cases, zstd-3 gets close enough to the “best” ratio without turning your CPU into a space heater.&lt;/p&gt;
&lt;h3 id=&#34;compression-speed&#34;&gt;Compression Speed&lt;/h3&gt;
&lt;p&gt;Snappy and LZ4 are fast. zstd-1, 3, and 9 kept up surprisingly well. gzip is predictably slow. zstd-19 made me question my life choices, I thought it might have frozen or got silently murdered by the OS. I’m not saying never use it, there are some use cases, but they’re likely few and far between.&lt;/p&gt;
&lt;h3 id=&#34;decompression-speed&#34;&gt;Decompression Speed&lt;/h3&gt;
&lt;p&gt;Snappy and LZ4 hit over 3.5GB/s. zstd held steady around 1GB/s across all levels. gzip stayed slow.&lt;/p&gt;
&lt;p&gt;If you need to read the same data multiple times Snappy and LZ4 are faster than gzip or zstd. But zstd isn’t slow enough to matter unless your volumes are huge.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;file-size-scaling&#34;&gt;File Size Scaling&lt;/h3&gt;
&lt;p&gt;Throughput went down as file size grew. Gzip was slow the whole time. zstd-19 was even slower and I didn&amp;rsquo;t run it for all file size, so it may have gone even more down.&lt;/p&gt;
&lt;p&gt;The others held up fairly well. Snappy stayed fastest, but none of them completely fell apart.&lt;/p&gt;
&lt;p&gt;Note: CPU was pinned at 100% during all runs. On a single-threaded, 16GB machine, there was probably some memory pressure too for the larger files. These results match what I’ve seen elsewhere but might be a bit exaggerated.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mamonas.dev/posts/which-compression-algorithm-saves-most/image-2.png&#34; alt=&#34;Compression Throughput vs File Size&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;storage-cost-s3&#34;&gt;Storage Cost (S3)&lt;/h3&gt;
&lt;p&gt;S3 Standard pricing in eu-central-1 is $0.0235/GB. At 500TB/month, codec choice can have a significant (based on your budged) impact on the cost. But if you&amp;rsquo;re only storing a few TB, this doesn’t matter much. At 100TB, you&amp;rsquo;re looking at maybe a few hundred bucks.&lt;/p&gt;
&lt;p&gt;Snappy/LZ4 would cost around $10.7K/month. zstd-3 lands near $9.7K for 500TBs. zstd-19 saves a bit more, but the compute cost and latency make it hard to justify. gzip is in the same ballpark, and we’ve already covered its performance.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://mamonas.dev/posts/which-compression-algorithm-saves-most/image-3.png&#34; alt=&#34;Projected Monthly S3 Cost by Codec at Scale&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;what-to-pick&#34;&gt;What to Pick?&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;For streaming&lt;/strong&gt;
Snappy or LZ4. Fast compression and decompression. Compression ratio better than nothing.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;For batch ETL or periodic jobs&lt;/strong&gt;
zstd-1 or zstd-3. Good balance between speed and size.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;For archival&lt;/strong&gt;
zstd-9 if you care for small gains. zstd-19 if you’re archiving something you hope nobody ever reads again.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;final-thoughts&#34;&gt;Final Thoughts&lt;/h2&gt;
&lt;p&gt;After my initial post, I assumed the real-life impact of LZ4 and zstd would be more obvious. But it turns out you need quite a bit of scale to feel it. In the future, I won’t be so quick to dismiss Snappy as it has its place. But it’s not the only viable option there is.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;d also like to benchmark compute cost in the future and see whether using zstd at scale is actually worth it for batch processes or if the additional compute time eats up your storage savings.&lt;/p&gt;
&lt;p&gt;Also keep in mind that your mileage might vary based on your data, compression is about finding patters and if there&amp;rsquo;s none, the result might be a larger file than you began with, so pick accordingly, maybe run a benchmark yourself.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Thank you for reading.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Compression Algorithms You Probably Inherited: gzip, Snappy, LZ4, zstd</title>
      <link>https://mamonas.dev/posts/compression-algorithms-you-probably-inherited/</link>
      <pubDate>Mon, 18 Aug 2025 21:45:14 +0300</pubDate>
      
      <guid>https://mamonas.dev/posts/compression-algorithms-you-probably-inherited/</guid>
      <description>&lt;h2 id=&#34;you-might-be-using-the-wrong-compression-algorithm&#34;&gt;You Might Be Using The Wrong Compression Algorithm&lt;/h2&gt;
&lt;p&gt;If you work in data engineering, you’ve probably used &lt;strong&gt;gzip&lt;/strong&gt;, &lt;strong&gt;Snappy&lt;/strong&gt;, &lt;strong&gt;LZ4&lt;/strong&gt;, or &lt;strong&gt;Zstandard (zstd)&lt;/strong&gt;. More likely - you inherited them. Either the person who set these defaults is long gone, there’s never enough time to revisit the choice, or things work well enough and you’d rather not duck around and find out otherwise.&lt;/p&gt;
&lt;p&gt;Most engineers stick with the defaults. Changing them feels risky. And let’s be honest - many don’t really know what these algorithms do or why one was chosen in the first place.&lt;/p&gt;</description>
      <content>&lt;h2 id=&#34;you-might-be-using-the-wrong-compression-algorithm&#34;&gt;You Might Be Using The Wrong Compression Algorithm&lt;/h2&gt;
&lt;p&gt;If you work in data engineering, you’ve probably used &lt;strong&gt;gzip&lt;/strong&gt;, &lt;strong&gt;Snappy&lt;/strong&gt;, &lt;strong&gt;LZ4&lt;/strong&gt;, or &lt;strong&gt;Zstandard (zstd)&lt;/strong&gt;. More likely - you inherited them. Either the person who set these defaults is long gone, there’s never enough time to revisit the choice, or things work well enough and you’d rather not duck around and find out otherwise.&lt;/p&gt;
&lt;p&gt;Most engineers stick with the defaults. Changing them feels risky. And let’s be honest - many don’t really know what these algorithms do or why one was chosen in the first place.&lt;/p&gt;
&lt;p&gt;I’ve been that person myself: &lt;em&gt;&amp;ldquo;Oh, we’re using Snappy? OK.&amp;rdquo;&lt;/em&gt; Never thinking to ask why or what else we could use.&lt;/p&gt;
&lt;p&gt;This post explains the most common compression algorithms, what makes them different, and when you should actually use each.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;why-compression-choices-matter&#34;&gt;Why Compression Choices Matter&lt;/h2&gt;
&lt;p&gt;Compression decisions aren’t just about saving space. They directly impact:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Storage costs&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CPU utilization&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Throughput&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Latency&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In modern pipelines — Kafka, Parquet, column stores, data lakes - the wrong compression algorithm can degrade all of these.&lt;/p&gt;
&lt;p&gt;Two metrics matter most:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Compression ratio&lt;/strong&gt;: How much smaller the data gets.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Throughput&lt;/strong&gt;: How quickly data can be compressed and decompressed.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Your workload - and whether you prioritize CPU, latency, or bandwidth - determines which trade-offs are acceptable.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;main-culprits&#34;&gt;Main Culprits&lt;/h2&gt;
&lt;h3 id=&#34;gzip&#34;&gt;gzip&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;What it is&lt;/strong&gt;: Uses the DEFLATE algorithm (LZ77 + Huffman coding).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Goal&lt;/strong&gt;: Good compression ratio. Compatibility.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt;: Slow to compress. Moderate decompression speed.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Strength&lt;/strong&gt;: Ubiquitous. Supported everywhere.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Weakness&lt;/strong&gt;: Outclassed in both speed and compression ratio by newer algorithms.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;When to use&lt;/strong&gt;: Archival, compatibility with legacy tools. Otherwise, avoid.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;snappy&#34;&gt;Snappy&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;What it is&lt;/strong&gt;: Developed by Google. Based on LZ77 without entropy coding.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Goal&lt;/strong&gt;: Maximize speed, not compression ratio.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt;: Very fast compression and decompression.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Strength&lt;/strong&gt;: Low CPU overhead. Stable. Production-proven at Google scale.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Weakness&lt;/strong&gt;: Larger compressed size than other options.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;When to use&lt;/strong&gt;: Real-time, low-CPU systems where latency matters more than storage. Or if you&amp;rsquo;re stuck with it.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lz4&#34;&gt;LZ4&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;What it is&lt;/strong&gt;: LZ77-based. Prioritizes speed.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Goal&lt;/strong&gt;: Fast compression and decompression with moderate compression ratio.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt;: &amp;gt; 500 MB/s compression. GB/s decompression.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Strength&lt;/strong&gt;: Extremely fast. Low CPU usage.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Weakness&lt;/strong&gt;: Compression ratio lower than gzip or zstd.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;When to use&lt;/strong&gt;: High-throughput, low-latency systems. Datacenter transfers. OLAP engines (DuckDB, Cassandra).&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;zstd-zstandard&#34;&gt;zstd (Zstandard)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;What it is&lt;/strong&gt;: Developed by Facebook. Combines LZ77, Huffman coding, and FSE.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Goal&lt;/strong&gt;: High compression ratio with fast speed.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt;: Compression 500+ MB/s. Decompression ~1500+ MB/s.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Strength&lt;/strong&gt;: Tunable. Balances speed and compression. Strong performance across data types.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Weakness&lt;/strong&gt;: Slightly more CPU than LZ4/Snappy at default settings.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;When to use&lt;/strong&gt;: General-purpose. Parquet files. Kafka. Data transfers. Usually the best all-around choice.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;strengths-and-weaknesses-at-a-glance&#34;&gt;Strengths and Weaknesses (At a Glance)&lt;/h2&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Algorithm&lt;/th&gt;
          &lt;th&gt;Compression Ratio&lt;/th&gt;
          &lt;th&gt;Compression Speed&lt;/th&gt;
          &lt;th&gt;Decompression Speed&lt;/th&gt;
          &lt;th&gt;Best For&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;gzip&lt;/td&gt;
          &lt;td&gt;Moderate&lt;/td&gt;
          &lt;td&gt;Slow&lt;/td&gt;
          &lt;td&gt;Moderate&lt;/td&gt;
          &lt;td&gt;Archival, web content&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Snappy&lt;/td&gt;
          &lt;td&gt;Low&lt;/td&gt;
          &lt;td&gt;Very Fast&lt;/td&gt;
          &lt;td&gt;Very Fast&lt;/td&gt;
          &lt;td&gt;Real-time, low-CPU systems&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;LZ4&lt;/td&gt;
          &lt;td&gt;Moderate&lt;/td&gt;
          &lt;td&gt;Extremely Fast&lt;/td&gt;
          &lt;td&gt;Extremely Fast&lt;/td&gt;
          &lt;td&gt;High-throughput, low-latency systems&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;zstd&lt;/td&gt;
          &lt;td&gt;High&lt;/td&gt;
          &lt;td&gt;Fast&lt;/td&gt;
          &lt;td&gt;Fast&lt;/td&gt;
          &lt;td&gt;General-purpose, Parquet, Kafka, data transfers&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;real-world-scenarios-when-to-use-what&#34;&gt;Real-World Scenarios: When to Use What&lt;/h2&gt;
&lt;h3 id=&#34;high-throughput-streaming-kafka&#34;&gt;High-throughput streaming (Kafka)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Use&lt;/strong&gt;: zstd or LZ4&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: zstd gives better compression with good speed. LZ4 if latency is critical and CPU is limited. Snappy is acceptable if inherited, but usually not optimal anymore.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;long-term-storage-parquet-s3&#34;&gt;Long-term storage (Parquet, S3)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Use&lt;/strong&gt;: zstd&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Best compression ratio reduces storage cost and IO. Slight CPU trade-off is acceptable.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;low-latency-querying-duckdb-cassandra&#34;&gt;Low-latency querying (DuckDB, Cassandra)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Use&lt;/strong&gt;: LZ4&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Prioritize decompression speed for fast queries. LZ4 is the common choice in OLAP engines.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cpumemory-constrained-environments&#34;&gt;CPU/memory constrained environments&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Use&lt;/strong&gt;: Snappy or LZ4&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Low CPU overhead is more important than compression ratio. zstd can still be used at low compression levels if needed.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;fast-network-low-compression-benefit-datacenter-file-transfer&#34;&gt;Fast network, low compression benefit (datacenter file transfer)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Use&lt;/strong&gt;: LZ4&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Minimal compression overhead. On fast networks, speed beats smaller file sizes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;slow-network-or-internet-transfers&#34;&gt;Slow network or internet transfers&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Use&lt;/strong&gt;: zstd&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Why&lt;/strong&gt;: Better compression reduces transfer time despite slightly higher CPU cost.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;what-to-remember&#34;&gt;What to Remember&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;No algorithm is best for every workload.&lt;/li&gt;
&lt;li&gt;zstd has become the Swiss Army knife of compression. Unless you have a good reason not to, it’s a smart pick.&lt;/li&gt;
&lt;li&gt;LZ4 is unbeatable when speed matters more than compression.&lt;/li&gt;
&lt;li&gt;Snappy is still acceptable in latency-sensitive, CPU-constrained setups but is generally being replaced.&lt;/li&gt;
&lt;li&gt;gzip remains for legacy systems or when maximum compatibility is required.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;whats-underneath-the-hood&#34;&gt;What&amp;rsquo;s Underneath The Hood&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;LZ77&lt;/strong&gt; - Replaces repeated sequences of data with references to earlier copies in the stream (sliding window). &lt;a href=&#34;https://en.wikipedia.org/wiki/LZ77_and_LZ78&#34;&gt;Wikipedia&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Huffman Coding&lt;/strong&gt; - A method of assigning shorter codes to more frequent data patterns to save space. &lt;a href=&#34;https://en.wikipedia.org/wiki/Huffman_coding&#34;&gt;Wikipedia&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;FSE (Finite State Entropy)&lt;/strong&gt; - An advanced entropy coding method that efficiently compresses sequences by balancing speed and compression ratio. &lt;a href=&#34;https://facebook.github.io/zstd/&#34;&gt;Facebook’s zstd Manual&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Why it matters&lt;/strong&gt;
Most compression algorithms combine finding patterns (LZ77) with efficient encoding (Huffman, FSE) to shrink data without losing information.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;closing-thoughts&#34;&gt;Closing Thoughts&lt;/h2&gt;
&lt;p&gt;Compression choices tend to stick around. There’s rarely time to revisit legacy pipelines, and if something works, it’s easy to assume it’s good enough. But if you can make the time, you’re now better equipped to review your defaults (I know I am.) - and see if a different choice might better fit your needs.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Thank you for reading.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>DuckDB: When You Don’t Need Spark (But Still Need SQL)</title>
      <link>https://mamonas.dev/posts/duckdb-when-you-dont-need-spark/</link>
      <pubDate>Mon, 18 Aug 2025 21:43:23 +0300</pubDate>
      
      <guid>https://mamonas.dev/posts/duckdb-when-you-dont-need-spark/</guid>
      <description>&lt;h2 id=&#34;the-problem&#34;&gt;The Problem&lt;/h2&gt;
&lt;p&gt;Too often, data engineering tasks that should be simple end up requiring heavyweight tools. Something breaks, or I need to explore a new dataset, and suddenly I’m firing up Spark or connecting to a cloud warehouse - even though the data easily fits on my laptop. That adds extra steps, slows things down, and costs more than it should. I wanted something simpler for local analytics that could still handle serious queries.&lt;/p&gt;</description>
      <content>&lt;h2 id=&#34;the-problem&#34;&gt;The Problem&lt;/h2&gt;
&lt;p&gt;Too often, data engineering tasks that should be simple end up requiring heavyweight tools. Something breaks, or I need to explore a new dataset, and suddenly I’m firing up Spark or connecting to a cloud warehouse - even though the data easily fits on my laptop. That adds extra steps, slows things down, and costs more than it should. I wanted something simpler for local analytics that could still handle serious queries.&lt;/p&gt;
&lt;h2 id=&#34;what-is-duckdb&#34;&gt;What Is DuckDB?&lt;/h2&gt;
&lt;p&gt;DuckDB is an open-source, in-process SQL OLAP database designed for analytics.&lt;/p&gt;
&lt;p&gt;It runs embedded inside applications, similar to SQLite, but optimized for analytical queries like joins, aggregations, and large scans.&lt;/p&gt;
&lt;p&gt;In short, it goes fast without adding the complexity of distributed systems.&lt;/p&gt;
&lt;h2 id=&#34;how-duckdb-achieves-high-performance&#34;&gt;How DuckDB Achieves High Performance&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Columnar Storage:&lt;/strong&gt;
Data is stored by columns, not rows. This lets queries scan only the data they need, cutting down IO.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Vectorized Execution:&lt;/strong&gt;
Processes data in batches (about 1000 rows at a time) to leverage CPU caching and SIMD instructions, reducing processing overhead.&lt;/p&gt;
&lt;p&gt;These two design choices allow DuckDB to handle complex analytical queries efficiently on a single machine.&lt;/p&gt;
&lt;h2 id=&#34;handling-large-datasets&#34;&gt;Handling Large Datasets&lt;/h2&gt;
&lt;p&gt;DuckDB dynamically manages memory and disk usage based on workload size:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;In-Memory Mode:&lt;/strong&gt; Keeps everything in RAM if possible.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Out-of-Core Mode:&lt;/strong&gt; Spills to disk if data exceeds memory.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Hybrid Execution:&lt;/strong&gt; Switches between modes automatically based on workload.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Persistent Storage:&lt;/strong&gt; Can save results in &lt;code&gt;.duckdb&lt;/code&gt; files for reuse.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;No manual configuration. No crashing on out-of-memory errors (Hi Pandas!).&lt;/p&gt;
&lt;h2 id=&#34;extensibility--concurrency&#34;&gt;Extensibility &amp;amp; Concurrency&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Single-writer, multiple-reader concurrency (MVCC).&lt;/li&gt;
&lt;li&gt;Growing ecosystem of extensions: Parquet, CSV, S3, HTTP endpoints, geospatial analytics.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;trade-offs-duckdb-vs-specialized-engines&#34;&gt;Trade-Offs: DuckDB vs Specialized Engines&lt;/h2&gt;
&lt;p&gt;DuckDB is flexible and fast, but:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;SQL Parsing Overhead:&lt;/strong&gt; Engines like Polars can be faster for simple dataframe operations.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;General Purpose Design:&lt;/strong&gt; Flexibility trades off some raw speed.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That said, for most data engineering tasks, the trade-off is worth it.&lt;/p&gt;
&lt;h2 id=&#34;where-duckdb-shines&#34;&gt;Where DuckDB Shines&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Local dataset exploration (when Pandas hits limits).&lt;/li&gt;
&lt;li&gt;CI and pipeline testing without Spark.&lt;/li&gt;
&lt;li&gt;Batch transformations on Parquet, CSV, and other formats.&lt;/li&gt;
&lt;li&gt;Lightweight production workflows.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;limits-to-keep-in-mind&#34;&gt;Limits to Keep in Mind&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Single-machine only - limited by your hardware.&lt;/li&gt;
&lt;li&gt;Not built for transactional workloads.&lt;/li&gt;
&lt;li&gt;SQL pipelines can get messy if not managed well.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;reflection-why-this-matters&#34;&gt;Reflection: Why This Matters&lt;/h2&gt;
&lt;p&gt;DuckDB helps bridge the gap between dataset size and engineering overhead.It’s not about replacing big tools, but avoiding them when you don’t need them.&lt;/p&gt;
&lt;p&gt;For tasks that outgrow Pandas or require complex queries, it’s a practical alternative to heavier tools.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Thanks for reading.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>kafka-replay-cli: A Lightweight Kafka Replay &amp; Debugging Tool</title>
      <link>https://mamonas.dev/posts/kafka-replay-cli/</link>
      <pubDate>Mon, 18 Aug 2025 21:41:41 +0300</pubDate>
      
      <guid>https://mamonas.dev/posts/kafka-replay-cli/</guid>
      <description>&lt;h2 id=&#34;project-links&#34;&gt;Project Links&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;GitHub&lt;/strong&gt;: &lt;a href=&#34;https://github.com/KonMam/kafka-replay-cli&#34;&gt;github.com/KonMam/kafka-replay-cli&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyPI&lt;/strong&gt;: &lt;a href=&#34;https://pypi.org/project/kafka-replay-cli/&#34;&gt;pypi.org/project/kafka-replay-cli&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;why-i-built-this&#34;&gt;Why I Built This&lt;/h2&gt;
&lt;p&gt;I wanted more hands-on &lt;a href=&#34;https://kafka.apache.org/&#34;&gt;Kafka&lt;/a&gt; experience - that&amp;rsquo;s the gist of it. Before this, I’d dealt with a few producers/consumers here and there, read the docs, and studied Kafka’s architectural design principles (very insightful read if you are interested in that sort of thing: &lt;a href=&#34;https://kafka.apache.org/documentation/&#34;&gt;https://kafka.apache.org/documentation/&lt;/a&gt;).
But there’s only so much you can learn with limited exposure and just reading, so I decided to spend some time tinkering and learning by doing.&lt;/p&gt;</description>
      <content>&lt;h2 id=&#34;project-links&#34;&gt;Project Links&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;GitHub&lt;/strong&gt;: &lt;a href=&#34;https://github.com/KonMam/kafka-replay-cli&#34;&gt;github.com/KonMam/kafka-replay-cli&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;PyPI&lt;/strong&gt;: &lt;a href=&#34;https://pypi.org/project/kafka-replay-cli/&#34;&gt;pypi.org/project/kafka-replay-cli&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;why-i-built-this&#34;&gt;Why I Built This&lt;/h2&gt;
&lt;p&gt;I wanted more hands-on &lt;a href=&#34;https://kafka.apache.org/&#34;&gt;Kafka&lt;/a&gt; experience - that&amp;rsquo;s the gist of it. Before this, I’d dealt with a few producers/consumers here and there, read the docs, and studied Kafka’s architectural design principles (very insightful read if you are interested in that sort of thing: &lt;a href=&#34;https://kafka.apache.org/documentation/&#34;&gt;https://kafka.apache.org/documentation/&lt;/a&gt;).
But there’s only so much you can learn with limited exposure and just reading, so I decided to spend some time tinkering and learning by doing.&lt;/p&gt;
&lt;h2 id=&#34;goals&#34;&gt;Goals&lt;/h2&gt;
&lt;p&gt;There were a few things I wanted to achieve with this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Get more Kafka experience - main goal.&lt;/li&gt;
&lt;li&gt;Integrate &lt;a href=&#34;https://duckdb.org/&#34;&gt;DuckDB&lt;/a&gt; - for the past year, I have seen a lot of hype around it and have started using it for some ad-hoc analysis. I enjoy using it, so I wanted to find a place for it.&lt;/li&gt;
&lt;li&gt;Have something to show at the end of it - meaning, find a real issue that people using Kafka might have and develop something around it, applying good practices.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;problem--mvp&#34;&gt;Problem &amp;amp; MVP&lt;/h2&gt;
&lt;p&gt;I needed to find a problem I could so-called &amp;lsquo;solve,&amp;rsquo; even if it had been done before. After some careful Googling and ChatGPT-ing, &lt;strong&gt;Kafka message replay&lt;/strong&gt; came up as something people either struggle with or need heavy tools to handle. The tool should be useful for someone who needs to reprocess events with filters or transformations, debugging, or migrating data between topics.&lt;/p&gt;
&lt;p&gt;The initial MVP I scoped was simple:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Basic replay of messages with filters.&lt;/li&gt;
&lt;li&gt;Ability to dump Kafka topic data.&lt;/li&gt;
&lt;li&gt;Query dumped data.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I wanted it lightweight, scriptable, and easy to use - no streaming engine, web UI, or over-engineering.&lt;/p&gt;
&lt;h2 id=&#34;architecture&#34;&gt;Architecture&lt;/h2&gt;
&lt;p&gt;The first decision I had to make was whether to use Python or Golang.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Arguments for Python&lt;/strong&gt; - I have the most experience with it and expected it would be easier and faster to develop.
&lt;strong&gt;Arguments for Golang&lt;/strong&gt; - In the long run, it would most likely be more performant. I would get more familiar with Golang.&lt;/p&gt;
&lt;p&gt;Due to my decision to have something tangible in a few days, I went with Python. Since it is a small tool and I didn’t know how much use it would get, I preferred not to worry about making it as performant as possible - premature optimization is the root of all evil, after all.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tools used for this project:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kafka - the core thing I wanted to learn. Using the &lt;code&gt;confluent_kafka&lt;/code&gt; Python package, as it had all the features I needed.&lt;/li&gt;
&lt;li&gt;DuckDB - see above.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://typer.tiangolo.com/&#34;&gt;Typer&lt;/a&gt; - a library for building CLI applications. I had never used it before but liked the look and ergonomics it offered.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arrow.apache.org/docs/python/parquet.html&#34;&gt;PyArrow for Parquet&lt;/a&gt; - efficient storage; I’m used to working with it, and DuckDB can read from it. For alternatives could have used JSON or Avro, but JSON is inefficient for larger data volumes. Avro - might add support in the future.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;features&#34;&gt;Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Dump Kafka topics into Parquet files&lt;/li&gt;
&lt;li&gt;Replay messages from Parquet back into Kafka&lt;/li&gt;
&lt;li&gt;Filter replays by timestamp range and key&lt;/li&gt;
&lt;li&gt;Optional throttling during replay&lt;/li&gt;
&lt;li&gt;Apply custom transform hooks to modify or skip messages&lt;/li&gt;
&lt;li&gt;Preview replays without sending messages using &lt;code&gt;--dry-run&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Control output verbosity with &lt;code&gt;--verbose&lt;/code&gt; and &lt;code&gt;--quiet&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Query message dumps with DuckDB SQL&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;lessons-learned&#34;&gt;Lessons Learned&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Kafka&lt;/strong&gt; - Not as intimidating as expected and quite enjoyable. Both the official Kafka CLI tools and the Python integrations are mature.
&lt;strong&gt;DuckDB&lt;/strong&gt; - Currently limited use in the project, but good for what it does. I might add more use for it in the future or remove it to reduce bloat if it isn’t utilized.
&lt;strong&gt;Typer&lt;/strong&gt; - Enjoyed working with it a lot. Super easy to get a CLI tool going.
&lt;strong&gt;Testing&lt;/strong&gt; - Used &lt;code&gt;pytest&lt;/code&gt;. For unit tests, I didn’t want Kafka running for each test, so I used &lt;code&gt;MagicMock&lt;/code&gt; and &lt;code&gt;monkeypatch&lt;/code&gt; to simulate real objects - techniques I’ll keep in my pocket for future. For integration testing, I spun up a Docker container with a Kafka broker to test real usage of the CLI using &lt;code&gt;subprocess&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Main takeaway:&lt;/strong&gt;
It’s important to figure out your goals and think about the architecture before you start mashing on the keyboard. Deciding the project scope and dependencies early let me focus on the main features. It’s always a balancing act: what’s core, what’s nice to have, and how much time you want to spend.&lt;/p&gt;
&lt;h2 id=&#34;outcome--reflection&#34;&gt;Outcome &amp;amp; Reflection&lt;/h2&gt;
&lt;p&gt;Did I get more Kafka experience? Yes.
Does the tool do what I set out to make it do? Yes.
Is it the best thing since sliced bread? Highly unlikely.
Are there better tools for this use case? Probably.&lt;/p&gt;
&lt;p&gt;At the end of the day, this was a learning experience and I had fun. If someone uses it - great. If no one does - also great, it just means that I didn&amp;rsquo;t spend enough time researching real usage problems.&lt;/p&gt;
&lt;h2 id=&#34;installation--usage&#34;&gt;Installation &amp;amp; Usage&lt;/h2&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install kafka-replay-cli
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kafka-replay-cli dump --help
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;kafka-replay-cli replay --help
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;hr&gt;
&lt;p&gt;Thank you for reading.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Kafka Producers Explained: Partitioning, Batching, and Reliability</title>
      <link>https://mamonas.dev/posts/kafka-producers-explained/</link>
      <pubDate>Mon, 18 Aug 2025 21:39:05 +0300</pubDate>
      
      <guid>https://mamonas.dev/posts/kafka-producers-explained/</guid>
      <description>&lt;p&gt;A Kafka producer is the entry point for all data written to Kafka. It sends records to specific topic partitions, defines batching behavior, and controls how reliably data is delivered.&lt;/p&gt;
&lt;p&gt;This post covers the behaviors and configurations that influence the producer: partitioning, batching, delivery guarantees, and message structure.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;what-does-a-kafka-producer-do&#34;&gt;What Does a Kafka Producer Do?&lt;/h2&gt;
&lt;p&gt;A Kafka producer is a client library integrated into applications to write messages to Kafka topics. When a message is sent, the producer determines:&lt;/p&gt;</description>
      <content>&lt;p&gt;A Kafka producer is the entry point for all data written to Kafka. It sends records to specific topic partitions, defines batching behavior, and controls how reliably data is delivered.&lt;/p&gt;
&lt;p&gt;This post covers the behaviors and configurations that influence the producer: partitioning, batching, delivery guarantees, and message structure.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;what-does-a-kafka-producer-do&#34;&gt;What Does a Kafka Producer Do?&lt;/h2&gt;
&lt;p&gt;A Kafka producer is a client library integrated into applications to write messages to Kafka topics. When a message is sent, the producer determines:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Which partition the message should go to&lt;/li&gt;
&lt;li&gt;How to serialize the message for Kafka&lt;/li&gt;
&lt;li&gt;Whether to batch it with others&lt;/li&gt;
&lt;li&gt;How many acknowledgments are required before the message is considered delivered&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Producers are designed to balance speed, reliability, ordering, and throughput. Optimizing for one might require to compromise another.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;partitioning-strategies-routing-messages-to-partitions&#34;&gt;Partitioning Strategies: Routing Messages to Partitions&lt;/h2&gt;
&lt;p&gt;Kafka topics are split into partitions. Every message sent by a producer is written to one partition. This decision is made by a partitioner function.&lt;/p&gt;
&lt;h3 id=&#34;with-a-key&#34;&gt;With a Key&lt;/h3&gt;
&lt;p&gt;If a message has a key, Kafka hashes it using the Murmur2 algorithm and assigns the message to a partition using:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;partition = hash(key) % number_of_partitions
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This ensures all messages with the same key go to the same partition. Kafka guarantees message order within a partition, so key-based partitioning is how per-key ordering is maintained.&lt;/p&gt;
&lt;h3 id=&#34;without-a-key&#34;&gt;Without a Key&lt;/h3&gt;
&lt;p&gt;If the key is null, Kafka uses one of two strategies:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Round-robin&lt;/strong&gt;: messages cycle through partitions in order. Used in older clients&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sticky partitioning&lt;/strong&gt;: the producer sends all messages to the same partition until the batch is sent, then picks a new one. Default in modern clients&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sticky partitioning improves batching efficiency while maintaining fair distribution over time.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;message-format-structure-and-serialization&#34;&gt;Message Format: Structure and Serialization&lt;/h2&gt;
&lt;p&gt;Kafka treats every message as a set of bytes. Each record includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Key (optional): used for partitioning. Serialized to bytes&lt;/li&gt;
&lt;li&gt;Value: the actual data payload. Serialized to bytes&lt;/li&gt;
&lt;li&gt;Headers (optional): metadata as key-value pairs&lt;/li&gt;
&lt;li&gt;Timestamp: assigned by the client or broker&lt;/li&gt;
&lt;li&gt;Partition + Offset: assigned by the broker after the message is stored&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kafka does not interpret or modify message content; it just stores and transmits byte arrays. Producers are responsible for serializing messages before sending them.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example (Python):&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;producer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; KafkaProducer(value_serializer&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; v: json&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;dumps(v)&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;encode(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Efficient serialization improves throughput and reduces broker load. Avoid inefficient formats like uncompressed JSON unless specifically required by system constraints.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;batching-and-compression-optimizing-throughput&#34;&gt;Batching and Compression: Optimizing Throughput&lt;/h2&gt;
&lt;p&gt;Sending one message per request is inefficient. Kafka producers batch multiple records together per partition before sending them to the broker.&lt;/p&gt;
&lt;h3 id=&#34;key-configuration-options&#34;&gt;Key Configuration Options&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;batch.size&lt;/code&gt;: maximum size in bytes for a batch. Larger batches improve compression and throughput, but increase memory usage&lt;/li&gt;
&lt;li&gt;&lt;code&gt;linger.ms&lt;/code&gt;: how long to wait before sending a batch, even if it is not full. Increases batching opportunities at the cost of latency&lt;/li&gt;
&lt;li&gt;&lt;code&gt;compression.type&lt;/code&gt;: compresses full batches. Options include &lt;code&gt;gzip&lt;/code&gt;, &lt;code&gt;lz4&lt;/code&gt;, &lt;code&gt;snappy&lt;/code&gt;, &lt;code&gt;zstd&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;code&gt;send()&lt;/code&gt; method is non-blocking. It queues the record in memory and returns immediately. The background sender thread flushes batches when &lt;code&gt;batch.size&lt;/code&gt; is reached or &lt;code&gt;linger.ms&lt;/code&gt; expires.&lt;/p&gt;
&lt;p&gt;Batching operates on a per-partition basis. As a result, applications that produce to a large number of partitions may experience reduced batching efficiency unless message flow is concentrated across fewer partitions.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;delivery-guarantees-configuring-reliability-and-ordering&#34;&gt;Delivery Guarantees: Configuring Reliability and Ordering&lt;/h2&gt;
&lt;p&gt;Kafka producers can trade reliability for speed using the &lt;code&gt;acks&lt;/code&gt; configuration:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;acks=0&lt;/code&gt;: fire and forget. Fastest, but data may be lost&lt;/li&gt;
&lt;li&gt;&lt;code&gt;acks=1&lt;/code&gt;: wait for leader. Reasonable balance for many use cases&lt;/li&gt;
&lt;li&gt;&lt;code&gt;acks=all&lt;/code&gt;: wait for all in-sync replicas. Safest, with higher latency&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ordering-and-retries&#34;&gt;Ordering and Retries&lt;/h3&gt;
&lt;p&gt;Kafka guarantees ordering within a single partition. To maintain strict ordering, ensure:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;All related messages share the same key&lt;/li&gt;
&lt;li&gt;&lt;code&gt;max.in.flight.requests.per.connection &amp;lt;= 1&lt;/code&gt; when retries are enabled (to prevent out-of-order writes during retries)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;idempotence-and-transactions&#34;&gt;Idempotence and Transactions&lt;/h2&gt;
&lt;p&gt;By default, producers use at-least-once semantics, meaning retries may cause duplicate messages. Kafka provides stronger guarantees where needed.&lt;/p&gt;
&lt;h3 id=&#34;idempotent-producer&#34;&gt;Idempotent Producer&lt;/h3&gt;
&lt;p&gt;Enable with &lt;code&gt;enable.idempotence=true&lt;/code&gt;. This prevents duplicates during retries by assigning each producer a unique ID and tracking sequence numbers per partition.&lt;/p&gt;
&lt;p&gt;This guarantees exactly-once delivery per partition, assuming the producer does not crash and restart with a new ID.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Use this when:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Downstream systems cannot deduplicate&lt;/li&gt;
&lt;li&gt;Every message must be uniquely written (for example, financial systems)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Avoid using high &lt;code&gt;max.in.flight&lt;/code&gt; values with idempotence if ordering matters.&lt;/p&gt;
&lt;h3 id=&#34;transactional-producer&#34;&gt;Transactional Producer&lt;/h3&gt;
&lt;p&gt;Transactional producers enable atomic writes across multiple partitions or topics.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Requires:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A configured &lt;code&gt;transactional.id&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Use of API methods: &lt;code&gt;begin_transaction()&lt;/code&gt;, &lt;code&gt;send()&lt;/code&gt;, &lt;code&gt;commit_transaction()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is critical for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Exactly-once event processing pipelines&lt;/li&gt;
&lt;li&gt;Kafka Streams applications&lt;/li&gt;
&lt;li&gt;Coordinating multiple topic writes as a single atomic unit&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Transactions ensure no duplicates, no partial writes, and consistent failure handling.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;A well-tuned Kafka producer is critical to balancing throughput, reliability, and resource efficiency. It&amp;rsquo;s important to understand your delivery requirements and system constraints before leaning into aggressive batching or strong guarantees as you trade higher throughput for it.&lt;/p&gt;
</content>
    </item>
    
    <item>
      <title>Kafka Consumers Explained: Pull, Offsets, and Parallelism</title>
      <link>https://mamonas.dev/posts/kafka-consumers-explained/</link>
      <pubDate>Mon, 18 Aug 2025 21:30:08 +0300</pubDate>
      
      <guid>https://mamonas.dev/posts/kafka-consumers-explained/</guid>
      <description>&lt;p&gt;Kafka is built for high throughput, scalability, and fault tolerance. At the core of this is its consumer model. Unlike traditional messaging systems, Kafka gives consumers full control over how they read data. This post explains how Kafka consumers work by focusing on three things: how they pull data, how offsets work, and how parallelism is achieved with consumer groups.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;pulling-data-from-kafka&#34;&gt;Pulling Data from Kafka&lt;/h2&gt;
&lt;p&gt;Kafka producers push data to brokers. Consumers pull data from brokers. This setup is intentional. It gives consumers control over how fast they process data.&lt;/p&gt;</description>
      <content>&lt;p&gt;Kafka is built for high throughput, scalability, and fault tolerance. At the core of this is its consumer model. Unlike traditional messaging systems, Kafka gives consumers full control over how they read data. This post explains how Kafka consumers work by focusing on three things: how they pull data, how offsets work, and how parallelism is achieved with consumer groups.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;pulling-data-from-kafka&#34;&gt;Pulling Data from Kafka&lt;/h2&gt;
&lt;p&gt;Kafka producers push data to brokers. Consumers pull data from brokers. This setup is intentional. It gives consumers control over how fast they process data.&lt;/p&gt;
&lt;p&gt;In push-based systems, if the producer is faster than the consumer, the consumer can get overwhelmed or crash. Kafka avoids this problem by letting consumers decide when to fetch data. This helps with backpressure and makes the system more reliable.&lt;/p&gt;
&lt;p&gt;Pulling also helps with batching. A consumer can fetch many messages in a single request. This reduces the number of network calls. In contrast, push systems must send each message one by one or hold back messages without knowing if the consumer is ready.&lt;/p&gt;
&lt;p&gt;One downside of pull-based systems is wasteful polling. A consumer might keep asking for data even if nothing is available. Kafka avoids this by letting the consumer wait until enough data is ready before responding. This keeps CPU usage low and throughput high.&lt;/p&gt;
&lt;p&gt;Kafka also avoids a model where brokers pull data from producers. That design would need every producer to store its own data. It would require more coordination and increase the risk of disk failure. Instead, Kafka stores data on the broker, where it can be managed and replicated more easily.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;how-kafka-offsets-work&#34;&gt;How Kafka Offsets Work&lt;/h2&gt;
&lt;p&gt;Kafka splits topics into partitions. Each message in a partition has a number called an offset. The offset marks the position of the message in the log.&lt;/p&gt;
&lt;p&gt;Offsets give consumers control. A consumer chooses where to start reading and can track what has already been processed. If a consumer crashes, it can pick up where it left off by using its last committed offset.&lt;/p&gt;
&lt;p&gt;Kafka does not track this progress for the consumer. The consumer is responsible for managing its own offsets. This is part of what makes Kafka scalable and efficient.&lt;/p&gt;
&lt;p&gt;By default, a consumer starts at offset zero. This means it will read all messages that are still available. It can also be configured to start at the latest offset to only read new data.&lt;/p&gt;
&lt;p&gt;Kafka only keeps data for a limited time. If a consumer tries to read from an offset that is too old, Kafka will return an error. In that case, the consumer must reset to the earliest or latest available offset.&lt;/p&gt;
&lt;h3 id=&#34;key-terms&#34;&gt;Key Terms&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Offset&lt;/strong&gt;: The position of a message in a partition.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Log End Offset&lt;/strong&gt;: The offset where the next message will be written.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Committed Offset&lt;/strong&gt;: The offset of the last message the consumer has finished processing.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;delivery-options&#34;&gt;Delivery Options&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;At-most-once&lt;/strong&gt;: The consumer commits the offset before processing. If it crashes during processing, the message is lost.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;At-least-once&lt;/strong&gt;: The consumer commits the offset after processing. If it crashes before committing, the message may be processed again.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Exactly-once&lt;/strong&gt;: This uses Kafka transactions. The message and its offset are written together. If anything fails, nothing is committed. This guarantees no duplication and no loss.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;parallelism-with-consumer-groups&#34;&gt;Parallelism with Consumer Groups&lt;/h2&gt;
&lt;p&gt;Kafka uses consumer groups to scale out processing. A consumer group is a set of consumers working together to read from a topic.&lt;/p&gt;
&lt;p&gt;Kafka assigns each partition to only one consumer in the group. This avoids duplication and ensures order within each partition.&lt;/p&gt;
&lt;p&gt;When the group changes (for example, when consumers are added or removed), Kafka reassigns partitions to the available consumers.&lt;/p&gt;
&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;100 partitions and 100 consumers: each consumer handles one partition.&lt;/li&gt;
&lt;li&gt;100 partitions and 50 consumers: each consumer handles two partitions.&lt;/li&gt;
&lt;li&gt;50 partitions and 100 consumers: only 50 consumers do work, the rest are idle.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kafka does not let multiple consumers read from the same partition in the same group. This would require the broker to manage shared state, which adds complexity. Instead, Kafka puts the responsibility on the consumer to track offsets. This makes the broker faster and simpler.&lt;/p&gt;
&lt;p&gt;The number of partitions controls how much you can scale out. More partitions allow for more parallelism. Choosing the right number of partitions is important for performance and resource usage.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Kafka gives consumers control over how they pull data, where they start, and how they scale. Pull-based reads avoid overload. Offsets make it easy to recover from failure. Consumer groups allow you to scale out processing.&lt;/p&gt;
&lt;p&gt;This design makes Kafka fast, reliable, and efficient at any scale.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;appendix-quick-reference&#34;&gt;Appendix: Quick Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Partition&lt;/strong&gt;: A subset of a topic. Used for parallel processing and message ordering.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Offset&lt;/strong&gt;: A number showing a message’s position in a partition.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Consumer Group&lt;/strong&gt;: A set of consumers that share the work of reading from a topic.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Rebalancing&lt;/strong&gt;: The process where Kafka reassigns partitions when consumers join or leave a group.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Delivery Types&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;At-most-once&lt;/em&gt;: Fast, but may lose messages.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;At-least-once&lt;/em&gt;: Reliable, but may duplicate messages.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Exactly-once&lt;/em&gt;: Most accurate, but needs Kafka transactions.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content>
    </item>
    
    <item>
      <title>How Kafka Achieves High Throughput: A Breakdown of Its Log-Centric Architecture</title>
      <link>https://mamonas.dev/posts/how-kafka-achieves-high-throughput/</link>
      <pubDate>Mon, 18 Aug 2025 20:13:35 +0300</pubDate>
      
      <guid>https://mamonas.dev/posts/how-kafka-achieves-high-throughput/</guid>
      <description>&lt;p&gt;Kafka routinely handles millions of messages per second on commodity hardware. This performance isn&amp;rsquo;t accidental. It stems from deliberate architectural choices centered around log-based storage, OS-level optimizations, and minimal coordination between readers and writers.&lt;/p&gt;
&lt;p&gt;This post breaks down the core mechanisms that enable Kafka&amp;rsquo;s high-throughput design.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;1-append-only-log-storage&#34;&gt;1. Append-Only Log Storage&lt;/h2&gt;
&lt;p&gt;Each Kafka topic is split into partitions, and each partition is an append-only log. It is essentially a durable, ordered sequence of messages that are immutable once written.&lt;/p&gt;</description>
      <content>&lt;p&gt;Kafka routinely handles millions of messages per second on commodity hardware. This performance isn&amp;rsquo;t accidental. It stems from deliberate architectural choices centered around log-based storage, OS-level optimizations, and minimal coordination between readers and writers.&lt;/p&gt;
&lt;p&gt;This post breaks down the core mechanisms that enable Kafka&amp;rsquo;s high-throughput design.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;1-append-only-log-storage&#34;&gt;1. Append-Only Log Storage&lt;/h2&gt;
&lt;p&gt;Each Kafka topic is split into partitions, and each partition is an append-only log. It is essentially a durable, ordered sequence of messages that are immutable once written.&lt;/p&gt;
&lt;p&gt;To manage growing data size efficiently, Kafka breaks each partition’s log into multiple segment files. A segment is a file on disk that stores a continuous range of messages. New messages are always written to the active segment using low-level system calls like &lt;code&gt;write()&lt;/code&gt;. This write lands in the OS page cache, not written to disk immediately.&lt;/p&gt;
&lt;p&gt;Kafka delays calling &lt;code&gt;fsync()&lt;/code&gt; to flush data to disk, relying instead on configurable flush policies (based on time or size). This reduces disk I/O and improves performance, at the cost of brief durability gaps. Kafka mitigates this through replication across brokers.&lt;/p&gt;
&lt;p&gt;Over time, when a segment reaches a size threshold, it is closed and a new one is created. Older segments become read-only and are subject to log retention, compaction, or deletion based on topic settings.&lt;/p&gt;
&lt;p&gt;By aligning its write path with sequential disk I/O, Kafka avoids random seeks entirely. This makes reads and writes fast and predictable, even on spinning disks, and scales well with data volume.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;2-outperforming-traditional-queues-with-sequential-io&#34;&gt;2. Outperforming Traditional Queues with Sequential I/O&lt;/h2&gt;
&lt;p&gt;Traditional messaging systems often manage message delivery using per-consumer tracking and persistence mechanisms that can result in random disk access, especially during acknowledgment, redelivery, or crash recovery. While these systems are efficient in memory, random I/O patterns on disk introduce performance bottlenecks. For spinning disks, a single seek can take around 10 milliseconds, and disks can only perform one seek at a time.&lt;/p&gt;
&lt;p&gt;Kafka sidesteps this entirely by relying on sequential I/O. Writes are appended, and reads proceed in order. This design significantly improves disk efficiency, especially under load.&lt;/p&gt;
&lt;p&gt;By decoupling performance from data volume and enabling concurrent read/write access, Kafka makes efficient use of low-cost storage hardware, such as commodity SATA drives, without sacrificing performance.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;3-speeding-up-seeks-with-lightweight-indexing&#34;&gt;3. Speeding Up Seeks with Lightweight Indexing&lt;/h2&gt;
&lt;p&gt;Each segment file is accompanied by lightweight offset and timestamp indexes. These allow consumers to seek directly to specific message positions without scanning entire files, ensuring fast lookup even on large datasets.&lt;/p&gt;
&lt;p&gt;Since Kafka consumers track their own offsets and messages are immutable, there is no need to update shared state for acknowledgments or deletions. This eliminates coordination between readers and writers, reducing contention and enabling true parallelism.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;4-batching-to-maximize-io-efficiency&#34;&gt;4. Batching to Maximize I/O Efficiency&lt;/h2&gt;
&lt;p&gt;High-throughput systems must avoid the overhead of processing one message at a time. Kafka uses a message set abstraction to batch messages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Producers group messages before sending them.&lt;/li&gt;
&lt;li&gt;Brokers perform a single disk write per batch.&lt;/li&gt;
&lt;li&gt;Consumers fetch large batches with a single network call.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This batching reduces system calls, disk seeks, and protocol overhead. As a result, throughput improves significantly.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;5-zero-copy-data-transfer-with-sendfile&#34;&gt;5. Zero-Copy Data Transfer with &lt;code&gt;sendfile()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Conventional data transfer involves multiple memory copies:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Disk to kernel space (page cache)&lt;/li&gt;
&lt;li&gt;Kernel to user space (application buffer)&lt;/li&gt;
&lt;li&gt;User space back to kernel (socket buffer)&lt;/li&gt;
&lt;li&gt;Kernel to NIC buffer (for network)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Kafka avoids this overhead using the &lt;code&gt;sendfile()&lt;/code&gt; system call. This enables zero-copy data transfer from the page cache directly to the network stack, bypassing user space entirely.&lt;/p&gt;
&lt;p&gt;This reduces CPU usage and memory pressure, allowing near wire-speed data transfer even under heavy load.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;6-long-term-retention-without-performance-loss&#34;&gt;6. Long-Term Retention Without Performance Loss&lt;/h2&gt;
&lt;p&gt;Kafka’s append-only log model enables long-term message retention, even for days or weeks, without degrading performance. Because reads and writes are decoupled, and messages are not mutated post-write, old data remains accessible without impacting current workloads.&lt;/p&gt;
&lt;p&gt;This supports powerful use cases like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Replaying messages for state recovery&lt;/li&gt;
&lt;li&gt;Late-arriving consumer processing&lt;/li&gt;
&lt;li&gt;Time-travel debugging and auditing&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Kafka’s high throughput is the result of system and architectural decisions that work together by design. Its log-centric model avoids random I/O, minimizes coordination, and takes full advantage of OS-level features like the page cache and zero-copy transfers.&lt;/p&gt;
&lt;p&gt;The result: Kafka handles massive data volumes not through abstract complexity, but by working with the OS instead of against it.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;appendix-key-terms&#34;&gt;Appendix: Key Terms&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;write()&lt;/code&gt;: A system call that transfers data from user space to the OS page cache.&lt;/li&gt;
&lt;li&gt;Page cache: A memory buffer managed by the kernel.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fsync()&lt;/code&gt;: Forces data in the page cache to be flushed to disk.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sendfile()&lt;/code&gt;: A system call that sends data from a file directly to the network without copying to user space.&lt;/li&gt;
&lt;li&gt;Sequential I/O: Reading or writing data in a linear order. Much faster than random I/O, especially on HDDs.&lt;/li&gt;
&lt;li&gt;Random I/O: Accessing data at non-contiguous disk locations. This causes performance degradation due to disk seeks.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Further Reading:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kafka.apache.org/documentation/#design&#34;&gt;Kafka Official Design Documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</content>
    </item>
    
  </channel>
</rss>
