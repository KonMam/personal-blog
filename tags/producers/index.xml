<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Producers on mamonas.dev</title>
    <link>https://mamonas.dev/tags/producers/</link>
    <description>Recent content in Producers on mamonas.dev</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 18 Aug 2025 21:39:05 +0300</lastBuildDate><atom:link href="https://mamonas.dev/tags/producers/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kafka Producers Explained: Partitioning, Batching, and Reliability</title>
      <link>https://mamonas.dev/posts/kafka-producers-explained/</link>
      <pubDate>Mon, 18 Aug 2025 21:39:05 +0300</pubDate>
      
      <guid>https://mamonas.dev/posts/kafka-producers-explained/</guid>
      <description>&lt;p&gt;A Kafka producer is the entry point for all data written to Kafka. It sends records to specific topic partitions, defines batching behavior, and controls how reliably data is delivered.&lt;/p&gt;
&lt;p&gt;This post covers the behaviors and configurations that influence the producer: partitioning, batching, delivery guarantees, and message structure.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;what-does-a-kafka-producer-do&#34;&gt;What Does a Kafka Producer Do?&lt;/h2&gt;
&lt;p&gt;A Kafka producer is a client library integrated into applications to write messages to Kafka topics. When a message is sent, the producer determines:&lt;/p&gt;</description>
      <content>&lt;p&gt;A Kafka producer is the entry point for all data written to Kafka. It sends records to specific topic partitions, defines batching behavior, and controls how reliably data is delivered.&lt;/p&gt;
&lt;p&gt;This post covers the behaviors and configurations that influence the producer: partitioning, batching, delivery guarantees, and message structure.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;what-does-a-kafka-producer-do&#34;&gt;What Does a Kafka Producer Do?&lt;/h2&gt;
&lt;p&gt;A Kafka producer is a client library integrated into applications to write messages to Kafka topics. When a message is sent, the producer determines:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Which partition the message should go to&lt;/li&gt;
&lt;li&gt;How to serialize the message for Kafka&lt;/li&gt;
&lt;li&gt;Whether to batch it with others&lt;/li&gt;
&lt;li&gt;How many acknowledgments are required before the message is considered delivered&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Producers are designed to balance speed, reliability, ordering, and throughput. Optimizing for one might require to compromise another.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;partitioning-strategies-routing-messages-to-partitions&#34;&gt;Partitioning Strategies: Routing Messages to Partitions&lt;/h2&gt;
&lt;p&gt;Kafka topics are split into partitions. Every message sent by a producer is written to one partition. This decision is made by a partitioner function.&lt;/p&gt;
&lt;h3 id=&#34;with-a-key&#34;&gt;With a Key&lt;/h3&gt;
&lt;p&gt;If a message has a key, Kafka hashes it using the Murmur2 algorithm and assigns the message to a partition using:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;partition = hash(key) % number_of_partitions
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This ensures all messages with the same key go to the same partition. Kafka guarantees message order within a partition, so key-based partitioning is how per-key ordering is maintained.&lt;/p&gt;
&lt;h3 id=&#34;without-a-key&#34;&gt;Without a Key&lt;/h3&gt;
&lt;p&gt;If the key is null, Kafka uses one of two strategies:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Round-robin&lt;/strong&gt;: messages cycle through partitions in order. Used in older clients&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sticky partitioning&lt;/strong&gt;: the producer sends all messages to the same partition until the batch is sent, then picks a new one. Default in modern clients&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Sticky partitioning improves batching efficiency while maintaining fair distribution over time.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;message-format-structure-and-serialization&#34;&gt;Message Format: Structure and Serialization&lt;/h2&gt;
&lt;p&gt;Kafka treats every message as a set of bytes. Each record includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Key (optional): used for partitioning. Serialized to bytes&lt;/li&gt;
&lt;li&gt;Value: the actual data payload. Serialized to bytes&lt;/li&gt;
&lt;li&gt;Headers (optional): metadata as key-value pairs&lt;/li&gt;
&lt;li&gt;Timestamp: assigned by the client or broker&lt;/li&gt;
&lt;li&gt;Partition + Offset: assigned by the broker after the message is stored&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kafka does not interpret or modify message content; it just stores and transmits byte arrays. Producers are responsible for serializing messages before sending them.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example (Python):&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;producer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;KafkaProducer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;value_serializer&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;lambda&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;n&#34;&gt;json&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dumps&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;encode&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;utf-8&amp;#39;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Efficient serialization improves throughput and reduces broker load. Avoid inefficient formats like uncompressed JSON unless specifically required by system constraints.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;batching-and-compression-optimizing-throughput&#34;&gt;Batching and Compression: Optimizing Throughput&lt;/h2&gt;
&lt;p&gt;Sending one message per request is inefficient. Kafka producers batch multiple records together per partition before sending them to the broker.&lt;/p&gt;
&lt;h3 id=&#34;key-configuration-options&#34;&gt;Key Configuration Options&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;batch.size&lt;/code&gt;: maximum size in bytes for a batch. Larger batches improve compression and throughput, but increase memory usage&lt;/li&gt;
&lt;li&gt;&lt;code&gt;linger.ms&lt;/code&gt;: how long to wait before sending a batch, even if it is not full. Increases batching opportunities at the cost of latency&lt;/li&gt;
&lt;li&gt;&lt;code&gt;compression.type&lt;/code&gt;: compresses full batches. Options include &lt;code&gt;gzip&lt;/code&gt;, &lt;code&gt;lz4&lt;/code&gt;, &lt;code&gt;snappy&lt;/code&gt;, &lt;code&gt;zstd&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;code&gt;send()&lt;/code&gt; method is non-blocking. It queues the record in memory and returns immediately. The background sender thread flushes batches when &lt;code&gt;batch.size&lt;/code&gt; is reached or &lt;code&gt;linger.ms&lt;/code&gt; expires.&lt;/p&gt;
&lt;p&gt;Batching operates on a per-partition basis. As a result, applications that produce to a large number of partitions may experience reduced batching efficiency unless message flow is concentrated across fewer partitions.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;delivery-guarantees-configuring-reliability-and-ordering&#34;&gt;Delivery Guarantees: Configuring Reliability and Ordering&lt;/h2&gt;
&lt;p&gt;Kafka producers can trade reliability for speed using the &lt;code&gt;acks&lt;/code&gt; configuration:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;acks=0&lt;/code&gt;: fire and forget. Fastest, but data may be lost&lt;/li&gt;
&lt;li&gt;&lt;code&gt;acks=1&lt;/code&gt;: wait for leader. Reasonable balance for many use cases&lt;/li&gt;
&lt;li&gt;&lt;code&gt;acks=all&lt;/code&gt;: wait for all in-sync replicas. Safest, with higher latency&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ordering-and-retries&#34;&gt;Ordering and Retries&lt;/h3&gt;
&lt;p&gt;Kafka guarantees ordering within a single partition. To maintain strict ordering, ensure:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;All related messages share the same key&lt;/li&gt;
&lt;li&gt;&lt;code&gt;max.in.flight.requests.per.connection &amp;lt;= 1&lt;/code&gt; when retries are enabled (to prevent out-of-order writes during retries)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;idempotence-and-transactions&#34;&gt;Idempotence and Transactions&lt;/h2&gt;
&lt;p&gt;By default, producers use at-least-once semantics, meaning retries may cause duplicate messages. Kafka provides stronger guarantees where needed.&lt;/p&gt;
&lt;h3 id=&#34;idempotent-producer&#34;&gt;Idempotent Producer&lt;/h3&gt;
&lt;p&gt;Enable with &lt;code&gt;enable.idempotence=true&lt;/code&gt;. This prevents duplicates during retries by assigning each producer a unique ID and tracking sequence numbers per partition.&lt;/p&gt;
&lt;p&gt;This guarantees exactly-once delivery per partition, assuming the producer does not crash and restart with a new ID.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Use this when:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Downstream systems cannot deduplicate&lt;/li&gt;
&lt;li&gt;Every message must be uniquely written (for example, financial systems)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Avoid using high &lt;code&gt;max.in.flight&lt;/code&gt; values with idempotence if ordering matters.&lt;/p&gt;
&lt;h3 id=&#34;transactional-producer&#34;&gt;Transactional Producer&lt;/h3&gt;
&lt;p&gt;Transactional producers enable atomic writes across multiple partitions or topics.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Requires:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A configured &lt;code&gt;transactional.id&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Use of API methods: &lt;code&gt;begin_transaction()&lt;/code&gt;, &lt;code&gt;send()&lt;/code&gt;, &lt;code&gt;commit_transaction()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is critical for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Exactly-once event processing pipelines&lt;/li&gt;
&lt;li&gt;Kafka Streams applications&lt;/li&gt;
&lt;li&gt;Coordinating multiple topic writes as a single atomic unit&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Transactions ensure no duplicates, no partial writes, and consistent failure handling.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;A well-tuned Kafka producer is critical to balancing throughput, reliability, and resource efficiency. It&amp;rsquo;s important to understand your delivery requirements and system constraints before leaning into aggressive batching or strong guarantees as you trade higher throughput for it.&lt;/p&gt;
</content>
    </item>
    
  </channel>
</rss>
